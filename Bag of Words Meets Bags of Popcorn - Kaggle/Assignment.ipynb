{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries and the train and test files\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:\\\\Hackathons\\\\Signzy-job\\\\labeledTrainData.tsv', delimiter=\"\\t\")\n",
    "test = pd.read_csv('D:\\\\Hackathons\\\\Signzy-job\\\\testData.tsv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "#shape of train and test files\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "sentiment    0\n",
       "review       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking for null values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing train data\n",
    "corpus = []\n",
    "for i in range(0,25000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['review'].values[i])  #keeping only alphabets\n",
    "    review = review.lower()  #lowering\n",
    "    review = review.split()\n",
    "    lemma = WordNetLemmatizer()\n",
    "    review = [lemma.lemmatize(word) for word in review if not word in set(stopwords.words('english'))] #removing stopwords\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    \n",
    "    \n",
    "#joining the cleaned reviews to the main train file and saving it as a csv file\n",
    "train['cleaned_review'] = corpus\n",
    "train.to_csv(\"cleaned_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing test data\n",
    "corpus_test = []\n",
    "for i in range(0,25000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test['review'].values[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    lemma = WordNetLemmatizer()\n",
    "    review = [lemma.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)\n",
    "\n",
    "    \n",
    "#joining the cleaned reviews to the main test file and saving it as a csv file\n",
    "test['cleaned_review'] = corpus_test\n",
    "test.to_csv(\"cleaned_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing csv files\n",
    "train = pd.read_csv(\"cleaned_train.csv\")\n",
    "test = pd.read_csv(\"cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['cleaned_review']\n",
    "y = train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X,test_X, train_y, test_y = train_test_split(X,y, test_size=0.3, random_state=0) #splitting into 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                          tokenizer = None,    \n",
    "                                          preprocessor = None,\n",
    "                                          ngram_range = (1, 1),\n",
    "                                          binary = False,\n",
    "                                          strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3334  455]\n",
      " [ 551 3160]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87      3789\n",
      "          1       0.87      0.85      0.86      3711\n",
      "\n",
      "avg / total       0.87      0.87      0.87      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.000064\n",
      "Recall variance: 0.000202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "bow_mnb = bag_of_words_vectorizer.fit_transform(train_X)\n",
    "bow_mnb_test = bag_of_words_vectorizer.transform(test_X)\n",
    "\n",
    "bow_mnb_classifier = MultinomialNB()\n",
    "bow_mnb_classifier.fit(bow_mnb, train_y)\n",
    "bow_mnb_prediction = bow_mnb_classifier.predict(bow_mnb_test)\n",
    "\n",
    "print(confusion_matrix(test_y,bow_mnb_prediction))\n",
    "print(\"\")\n",
    "print(classification_report(test_y,bow_mnb_prediction))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, bow_mnb_prediction, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, bow_mnb_prediction, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3376  413]\n",
      " [ 680 3031]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86      3789\n",
      "          1       0.88      0.82      0.85      3711\n",
      "\n",
      "avg / total       0.86      0.85      0.85      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.000570\n",
      "Recall variance: 0.001378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bow_bnb = bag_of_words_vectorizer.fit_transform(train_X)\n",
    "bow_bnb_test = bag_of_words_vectorizer.transform(test_X)\n",
    "\n",
    "\n",
    "bow_bnb_classifier = BernoulliNB()\n",
    "bow_bnb_classifier.fit(bow_bnb, train_y)\n",
    "bow_bnb_prediction = bow_bnb_classifier.predict(bow_bnb_test)\n",
    "\n",
    "print(confusion_matrix(test_y,bow_bnb_prediction))\n",
    "print(classification_report(test_y,bow_bnb_prediction))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, bow_bnb_prediction, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, bow_bnb_prediction, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3294  495]\n",
      " [ 438 3273]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.87      0.88      3789\n",
      "          1       0.87      0.88      0.88      3711\n",
      "\n",
      "avg / total       0.88      0.88      0.88      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.000049\n",
      "Recall variance: 0.000040\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "bow_lr = bag_of_words_vectorizer.fit_transform(train_X)\n",
    "bow_lr_test = bag_of_words_vectorizer.transform(test_X)\n",
    "lr.fit(bow_lr, train_y)\n",
    "bow_lr_pred = lr.predict(bow_lr_test)\n",
    "\n",
    "print(confusion_matrix(test_y,bow_lr_pred))\n",
    "print(classification_report(test_y,bow_lr_pred))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, bow_lr_pred, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, bow_lr_pred, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3236  553]\n",
      " [ 524 3187]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.86      3789\n",
      "          1       0.85      0.86      0.86      3711\n",
      "\n",
      "avg / total       0.86      0.86      0.86      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.000018\n",
      "Recall variance: 0.000006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "bow_rf = bag_of_words_vectorizer.fit_transform(train_X)\n",
    "bow_rf_test = bag_of_words_vectorizer.transform(test_X)\n",
    "rf.fit(bow_rf, train_y)\n",
    "bow_rf_pred = rf.predict(bow_rf_test)\n",
    "\n",
    "print(confusion_matrix(test_y,bow_rf_pred))\n",
    "print(classification_report(test_y,bow_rf_pred))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, bow_rf_pred, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, bow_rf_pred, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5: GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2887  902]\n",
      " [ 494 3217]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.76      0.81      3789\n",
      "          1       0.78      0.87      0.82      3711\n",
      "\n",
      "avg / total       0.82      0.81      0.81      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.001328\n",
      "Recall variance: 0.002753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "bow_gbc = bag_of_words_vectorizer.fit_transform(train_X)\n",
    "bow_gbc_test = bag_of_words_vectorizer.transform(test_X)\n",
    "gbc.fit(bow_gbc, train_y)\n",
    "bow_gbc_pred = gbc.predict(bow_gbc_test)\n",
    "\n",
    "print(confusion_matrix(test_y,bow_gbc_pred))\n",
    "print(classification_report(test_y,bow_gbc_pred))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, bow_gbc_pred, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, bow_gbc_pred, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 6: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2887  902]\n",
      " [ 494 3217]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.76      0.81      3789\n",
      "          1       0.78      0.87      0.82      3711\n",
      "\n",
      "avg / total       0.82      0.81      0.81      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.001328\n",
      "Recall variance: 0.002753\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "bow_xgb = bag_of_words_vectorizer.fit_transform(train_X)\n",
    "bow_xgb_test = bag_of_words_vectorizer.transform(test_X)\n",
    "xgb.fit(bow_xgb, train_y)\n",
    "bow_xgb_pred = gbc.predict(bow_xgb_test)\n",
    "\n",
    "print(confusion_matrix(test_y,bow_xgb_pred))\n",
    "print(classification_report(test_y,bow_xgb_pred))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, bow_xgb_pred, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, bow_xgb_pred, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting best model to go forward: Logistic Regression [Kaggle Public LB Score: 85.536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(test_text_bow)\n",
    "predicted = pd.DataFrame()\n",
    "predicted['id'] = test['id']\n",
    "predicted['sentiment'] = pred\n",
    "predicted.to_csv(\"lr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf Vectorizer and setting maximum features to be used at 10,000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                           tokenizer = None,\n",
    "                                           preprocessor = None,\n",
    "                                           ngram_range = (1,1),\n",
    "                                           strip_accents = 'unicode',\n",
    "                                           max_features = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3333  456]\n",
      " [ 372 3339]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.88      0.89      3789\n",
      "          1       0.88      0.90      0.89      3711\n",
      "\n",
      "avg / total       0.89      0.89      0.89      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.000098\n",
      "Recall variance: 0.000101\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf = LogisticRegression()\n",
    "lr_tfidf_train1 = tfidf_vectorizer.fit_transform(train_X)\n",
    "lr_tfidf_test1 = tfidf_vectorizer.transform(test_X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "data_tfidf_lr = tfidf_transformer.fit_transform(lr_tfidf_train1)\n",
    "data_tfidf_test_lr = tfidf_transformer.transform(lr_tfidf_test1)\n",
    "\n",
    "lr_tfidf.fit(data_tfidf_lr, train_y)\n",
    "lr_tfidf_pred1 = lr_tfidf.predict(data_tfidf_test_lr)\n",
    "\n",
    "print(confusion_matrix(test_y,lr_tfidf_pred1))\n",
    "print(classification_report(test_y,lr_tfidf_pred1))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, lr_tfidf_pred1, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, lr_tfidf_pred1, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_bow_10000feat = tfidf_vectorizer.transform(test_text)\n",
    "test_text_bow_10000feat = tfidf_transformer.transform(test_text_bow_10000feat)\n",
    "pred = lr_tfidf.predict(test_text_bow_10000feat)\n",
    "predicted = pd.DataFrame()\n",
    "predicted['id'] = test['id']\n",
    "predicted['sentiment'] = pred\n",
    "predicted.to_csv(\"lr_10000feat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Public LB Score: 87.724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-Gram (2,2) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3107  682]\n",
      " [ 562 3149]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.82      0.83      3789\n",
      "          1       0.82      0.85      0.84      3711\n",
      "\n",
      "avg / total       0.83      0.83      0.83      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.000154\n",
      "Recall variance: 0.000204\n"
     ]
    }
   ],
   "source": [
    "ngram_bi = CountVectorizer(analyzer = \"word\",\n",
    "                                           tokenizer = None,\n",
    "                                           preprocessor = None,\n",
    "                                           ngram_range = (2,2),\n",
    "                                           strip_accents = 'unicode',\n",
    "                                           max_features = 10000)\n",
    "\n",
    "\n",
    "\n",
    "ngram_bi_train = ngram_bi.fit_transform(train_X)\n",
    "ngram_bi_test = ngram_bi.transform(test_X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "ngram_bi_tfidf = tfidf_transformer.fit_transform(ngram_bi_train)\n",
    "ngram_bi_tfidf_test = tfidf_transformer.transform(ngram_bi_test)\n",
    "\n",
    "lr_tfidf.fit(ngram_bi_tfidf, train_y)\n",
    "ngram_bi_tfidf_pred = lr_tfidf.predict(ngram_bi_tfidf_test)\n",
    "\n",
    "print(confusion_matrix(test_y,ngram_bi_tfidf_pred))\n",
    "print(classification_report(test_y,ngram_bi_tfidf_pred))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, ngram_bi_tfidf_pred, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, ngram_bi_tfidf_pred, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tri-Gram (3,3) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2409 1380]\n",
      " [ 780 2931]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.64      0.69      3789\n",
      "          1       0.68      0.79      0.73      3711\n",
      "\n",
      "avg / total       0.72      0.71      0.71      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.001426\n",
      "Recall variance: 0.005931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ngram_tri = CountVectorizer(analyzer = \"word\",\n",
    "                                           tokenizer = None,\n",
    "                                           preprocessor = None,\n",
    "                                           ngram_range = (3,3),\n",
    "                                           strip_accents = 'unicode',\n",
    "                                           max_features = 10000)\n",
    "\n",
    "\n",
    "ngram_tri_train = ngram_tri.fit_transform(train_X)\n",
    "ngram_tri_test = ngram_tri.transform(test_X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "ngram_tri_tfidf = tfidf_transformer.fit_transform(ngram_tri_train)\n",
    "ngram_tri_tfidf_test = tfidf_transformer.transform(ngram_tri_test)\n",
    "\n",
    "lr_tfidf.fit(ngram_tri_tfidf, train_y)\n",
    "ngram_tri_tfidf_pred = lr_tfidf.predict(ngram_tri_tfidf_test)\n",
    "\n",
    "print(confusion_matrix(test_y,ngram_tri_tfidf_pred))\n",
    "print(classification_report(test_y,ngram_tri_tfidf_pred))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, ngram_tri_tfidf_pred, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, ngram_tri_tfidf_pred, average=None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uni-bi Gram (1,2) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3332  457]\n",
      " [ 381 3330]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.88      0.89      3789\n",
      "          1       0.88      0.90      0.89      3711\n",
      "\n",
      "avg / total       0.89      0.89      0.89      7500\n",
      "\n",
      "\n",
      "Precision variance: 0.000082\n",
      "Recall variance: 0.000081\n"
     ]
    }
   ],
   "source": [
    "ngram_unibi = CountVectorizer(analyzer = \"word\",\n",
    "                                           tokenizer = None,\n",
    "                                           preprocessor = None,\n",
    "                                           ngram_range = (1,2),\n",
    "                                           strip_accents = 'unicode',\n",
    "                                           max_features = 10000)\n",
    "\n",
    "\n",
    "ngram_unibi_train = ngram_unibi.fit_transform(train_X)\n",
    "ngram_unibi_test = ngram_unibi.transform(test_X)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "ngram_unibi_tfidf = tfidf_transformer.fit_transform(ngram_unibi_train)\n",
    "ngram_unibi_tfidf_test = tfidf_transformer.transform(ngram_unibi_test)\n",
    "\n",
    "lr_tfidf.fit(ngram_unibi_tfidf, train_y)\n",
    "ngram_unibi_tfidf_pred = lr_tfidf.predict(ngram_unibi_tfidf_test)\n",
    "\n",
    "print(confusion_matrix(test_y,ngram_unibi_tfidf_pred))\n",
    "print(classification_report(test_y,ngram_unibi_tfidf_pred))\n",
    "print(\"\")\n",
    "print('Precision variance: %f' %(np.var(precision_score(test_y, ngram_unibi_tfidf_pred, average=None))))\n",
    "print('Recall variance: %f' %(np.var(recall_score(test_y, ngram_unibi_tfidf_pred, average=None))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Public LB Score: 88.056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test['cleaned_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_bow_10000feat = ngram_unibi.transform(test_text)\n",
    "test_text_bow_10000feat = tfidf_transformer.transform(test_text_bow_10000feat)\n",
    "pred = lr_tfidf.predict(test_text_bow_10000feat)\n",
    "predicted = pd.DataFrame()\n",
    "predicted['id'] = test['id']\n",
    "predicted['sentiment'] = pred\n",
    "predicted.to_csv(\"lr_10000feat_unibi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking cross-validation score for the best model till now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import explained_variance_score, make_scorer\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def plot_curve(model, train, title):\n",
    "    model.fit(train, y)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, train, y, n_jobs=-1, cv=5, train_sizes=np.linspace(.1, 1., 10), verbose=0)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training samples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend()\n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the test file accordingly..\n",
    "train_file = ngram_unibi.transform(X)\n",
    "train_file = tfidf_transformer.transform(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve(lr_tfidf, train_file, \"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 2.7825594022071245\n"
     ]
    }
   ],
   "source": [
    "##### Penalty and C\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = [np.logspace(0, 4, 10)]\n",
    "\n",
    "hyperparameters1 = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(lr_tfidf, hyperparameters1, cv=5, verbose=0) \n",
    "best_model = clf.fit(train_file, y)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict(test_text_bow_10000feat)\n",
    "predicted = pd.DataFrame()\n",
    "predicted['id'] = test['id']\n",
    "predicted['sentiment'] = pred\n",
    "predicted.to_csv(\"hptuning1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Public LB Score: 88.384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 2\n",
      "Best tol: 0.1\n"
     ]
    }
   ],
   "source": [
    "##### Penalty, C and tol\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = [0.001,0.01,0.1,1,2,3,4,5]\n",
    "tol = [0.00001,0.0001,0.001,0.01,0.1]\n",
    "\n",
    "hyperparameters2 = dict(C=C, penalty=penalty, tol=tol)\n",
    "clf = GridSearchCV(lr_tfidf, hyperparameters2, cv=5, verbose=0) \n",
    "best_model2 = clf.fit(train_file, y)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model2.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model2.best_estimator_.get_params()['C'])\n",
    "print('Best tol:', best_model2.best_estimator_.get_params()['tol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model2.predict(test_text_bow_10000feat)\n",
    "predicted = pd.DataFrame()\n",
    "predicted['id'] = test['id']\n",
    "predicted['sentiment'] = pred\n",
    "predicted.to_csv(\"hptuning2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Public LB Score: 88.452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installation_File\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\Installation_File\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 2\n",
      "Best tol: 0.001\n",
      "Best solver: sag\n"
     ]
    }
   ],
   "source": [
    "##### solver, C and tol\n",
    "\n",
    "solver = ['newton-cg', 'lbfgs', 'sag']\n",
    "C = [0.001,0.01,0.1,1,2,3,4,5]\n",
    "tol = [0.00001,0.0001,0.001,0.01,0.1]\n",
    "\n",
    "hyperparameters3 = dict(C=C, tol=tol, solver=solver)\n",
    "clf = GridSearchCV(lr_tfidf, hyperparameters3, cv=5, verbose=0) \n",
    "best_model3 = clf.fit(train_file, y)\n",
    "\n",
    "# View best hyperparameters\n",
    "\n",
    "print('Best C:', best_model3.best_estimator_.get_params()['C'])\n",
    "print('Best tol:', best_model3.best_estimator_.get_params()['tol'])\n",
    "print('Best solver:', best_model3.best_estimator_.get_params()['solver'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model3.predict(test_text_bow_10000feat)\n",
    "predicted = pd.DataFrame()\n",
    "predicted['id'] = test['id']\n",
    "predicted['sentiment'] = pred\n",
    "predicted.to_csv(\"hptuning3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Public LB Score: 88.464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='sag', tol=0.001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(C=2, tol= 0.001, solver= 'sag')\n",
    "print(logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
